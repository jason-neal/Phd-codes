{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azores poster plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import Obtain_Telluric as obt\n",
    "from Get_filenames import get_filenames\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Bokeh modules for interactive plotting\n",
    "import bokeh.io\n",
    "import bokeh.mpl\n",
    "import bokeh.plotting\n",
    "%config InlineBackend.figure_formats = {'svg',}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Bokeh for inline viewing\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters to alter to change spectra seen\n",
    "chip_num = 1\n",
    "obs_num = \"1\"\n",
    "ref_num = \"3\"\n",
    "target = \"HD30501-\" + obs_num\n",
    "reference_target = \"HD30501-\"+ ref_num    # should be different from target\n",
    "\n",
    "if target == reference_target:\n",
    "   raise ValueError(\"Reference target should be different from target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### Dracs data\n",
    "dracs_path = \"/home/jneal/Phd/data/Crires/BDs-DRACS/{0}/Combined_Nods/\".format(target)\n",
    "#dracs_path = \"C:/Users/Jason/Documents/PhD/Phd-codes/Notebooks/HD30501_data/{0}/\".format(obs_num)\n",
    "#dracs_path = \"../HD30501_data/{0}\".format(obs_num)\n",
    "dracs_name = get_filenames(dracs_path, \"CRIRE.*\",\"*{}.nod.ms.norm.sum.wavecal.fits\".format(chip_num))\n",
    "\n",
    "dracs_name = dracs_path + dracs_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dracs data load\n",
    "\n",
    "#dracs_data = fits.getdata(dracs_names[Chip_num-1])\n",
    "#dracs_hdr = fits.getheader(dracs_names[Chip_num-1]) \n",
    "dracs_data = fits.getdata(dracs_name)\n",
    "dracs_hdr = fits.getheader(dracs_name) \n",
    "\n",
    "dracs_wl = dracs_data[\"Wavelength\"]\n",
    "dracs_I = dracs_data[\"Extracted_DRACS\"]\n",
    "\n",
    "# normalize dracs\n",
    "maxes = dracs_I[(dracs_I < 1.2)].argsort()[-50:][::-1]\n",
    "dracs_I = dracs_I / np.median(dracs_I[maxes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load tapas file\n",
    "tapas_path = dracs_path + \"../Telluric_files/\"\n",
    "tapas_name = get_filenames(tapas_path, \"tapas_*\",\"*ReqId_10*\")[0]\n",
    "\n",
    "Tapas_data, Tapas_hdr = obt.load_telluric(tapas_path, tapas_name)\n",
    "tell_wl = Tapas_data[0]\n",
    "tell_I = Tapas_data[1]\n",
    "\n",
    "# normalize dracs\n",
    "maxes = tell_I[(tell_I < 1.2)].argsort()[-50:][::-1]\n",
    "#tell_I = tell_I / np.median(tell_I[maxes])\n",
    "\n",
    "#wl limit\n",
    "wlmask = (tell_wl > dracs_wl[0]/1.0001) & (tell_wl < dracs_wl[-1]*1.0001)\n",
    "tell_wl = tell_wl[wlmask]\n",
    "tell_I = tell_I[wlmask] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected values\n",
    "#dracs_path = \"/home/jneal/Phd/data/Crires/BDs-DRACS/{0}/Combined_Nods/\".format(target)\n",
    "#dracs_path = \"../HD30501_data/{0}\".format(obs_num)\n",
    "#dracs_path = \"C:/Users/Jason/Documents/PhD/Phd-codes/Notebooks/HD30501_data/{0}/\".format(obs_num)\n",
    "\n",
    "tellcorr_name = get_filenames(dracs_path, \"CRIRE.*\",\"*{}.nod.ms.norm.sum.wavecal.tellcorr.fits\".format(chip_num))\n",
    "h20tellcorr_name = get_filenames(dracs_path, \"CRIRE.*\",\"*{}.nod.ms.norm.sum.wavecal.h2otellcorr.fits\".format(chip_num))\n",
    "print(tellcorr_name)\n",
    "tellcorr_name = dracs_path + tellcorr_name[0]\n",
    "h20tellcorr_name = dracs_path + h20tellcorr_name[0]\n",
    "\n",
    "tellcorr_data = fits.getdata(tellcorr_name)\n",
    "#print(tellcorr_data.columns)\n",
    "tellcorr_hdr = fits.getheader(tellcorr_name) \n",
    "tellcorr_wl = tellcorr_data[\"Wavelength\"]\n",
    "tellcorr_I = tellcorr_data[\"Corrected_DRACS\"]\n",
    "tellcorr_tell = tellcorr_data[\"Interpolated_Tapas\"]   # for masking\n",
    "\n",
    "h20tellcorr_data = fits.getdata(h20tellcorr_name)\n",
    "#print(h20tellcorr_data.columns)\n",
    "h20tellcorr_hdr = fits.getheader(h20tellcorr_name) \n",
    "h20tellcorr_wl = h20tellcorr_data[\"Wavelength\"]\n",
    "h20tellcorr_I = h20tellcorr_data[\"Corrected_DRACS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Reference Target\n",
    "Also Berv corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference data \n",
    "# Same as above just a different target\n",
    "reference_path = \"/home/jneal/Phd/data/Crires/BDs-DRACS/{0}/Combined_Nods/\".format(reference_target)\n",
    "#reference_path = \"C:/Users/Jason/Documents/PhD/Phd-codes/Notebooks/HD30501_data/{0}/\".format(ref_num)\n",
    "reftellcorr_name = get_filenames(reference_path, \"CRIRE.*\",\"*{}.nod.ms.norm.sum.wavecal.tellcorr.fits\".format(chip_num))\n",
    "refh20tellcorr_name = get_filenames(reference_path, \"CRIRE.*\",\"*{}.nod.ms.norm.sum.wavecal.h2otellcorr.fits\".format(chip_num))\n",
    "\n",
    "######################################3 TESTING only\n",
    "#reference_path = \"/home/jneal/Phd/data/Crires/BDs-DRACS/{0}/Combined_Nods/Bervcorrected_tapas/\".format(reference_target)\n",
    "#reftellcorr_name = get_filenames(reference_path, \"CRIRE.*\",\"*{}.nod.ms.norm.sum.wavecal.tellcorr.test.fits\".format(chip_num))\n",
    "#refh20tellcorr_name = get_filenames(reference_path, \"CRIRE.*\",\"*{}.nod.ms.norm.sum.wavecal.tellcorr.test.fits\".format(chip_num))\n",
    "\n",
    "###########################################\n",
    "print(reftellcorr_name)\n",
    "\n",
    "reftellcorr_name = reference_path + reftellcorr_name[0]\n",
    "refh20tellcorr_name = reference_path + refh20tellcorr_name[0]\n",
    "\n",
    "reftellcorr_data = fits.getdata(reftellcorr_name)\n",
    "reftellcorr_hdr = fits.getheader(reftellcorr_name) \n",
    "reftellcorr_wl = reftellcorr_data[\"Wavelength\"]\n",
    "reftellcorr_I = reftellcorr_data[\"Corrected_DRACS\"]\n",
    "reftellcorr_tell = reftellcorr_data[\"Interpolated_Tapas\"]   # for masking\n",
    "\n",
    "refh20tellcorr_data = fits.getdata(refh20tellcorr_name)\n",
    "refh20tellcorr_hdr = fits.getheader(refh20tellcorr_name) \n",
    "refh20tellcorr_wl = h20tellcorr_data[\"Wavelength\"]\n",
    "refh20tellcorr_I = h20tellcorr_data[\"Corrected_DRACS\"]\n",
    "refh20tellcorr_tell = h20tellcorr_data[\"Interpolated_Tapas\"]  # for masking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make barycorr fucntion\n",
    "import time \n",
    "import datetime\n",
    "from PyAstronomy import pyasl\n",
    "\n",
    "def barycorr_CRIRES(wavelength, flux, header, extra_offset=None):\n",
    "    #\"\"\"\n",
    "    #Calculate Heliocenteric correction values and apply to spectrum.\n",
    "   \n",
    "    #SHOULD test again with bary and see what the  difference is.\n",
    "    #\"\"\"\n",
    "\n",
    "    longitude = float(header[\"HIERARCH ESO TEL GEOLON\"])\n",
    "    latitude = float(header[\"HIERARCH ESO TEL GEOLAT\"])\n",
    "    altitude = float(header[\"HIERARCH ESO TEL GEOELEV\"])\n",
    "\n",
    "    ra = header[\"RA\"]    # CRIRES RA already in degrees \n",
    "    dec = header[\"DEC\"]  # CRIRES hdr DEC already in degrees\n",
    "\n",
    "    # Pyastronomy helcorr needs the time of observation in julian Days\n",
    "    ##########################################################################################\n",
    "    Time =  header[\"DATE-OBS\"]    # Observing date  '2012-08-02T08:47:30.8425'\n",
    "    # Get Average time **** from all raw files!!!  #################################################################\n",
    "\n",
    "    wholetime, fractionaltime = Time.split(\".\")\n",
    "    Time_time = time.strptime(wholetime, \"%Y-%m-%dT%H:%M:%S\")\n",
    "    dt = datetime.datetime(*Time_time[:6])   # Turn into datetime object\n",
    "    # Account for fractions of a second\n",
    "    seconds_fractionalpart = float(\"0.\" + fractionaltime) / (24*60*60)   # Divide by seconds in a day\n",
    "\n",
    "    # Including the fractional part of seconds changes pyasl.helcorr RV by the order of 1cm/s\n",
    "    jd  = pyasl.asl.astroTimeLegacy.jdcnv(dt) + seconds_fractionalpart\n",
    "\n",
    "    # Calculate helocentric velocity\n",
    "    helcorr = pyasl.helcorr(longitude, latitude, altitude, ra, dec, jd, debug=False)\n",
    "    \n",
    "    if extra_offset:\n",
    "        print(\"Warning!!!! have included a manual offset for testing\")\n",
    "        helcorr_val = helcorr[0] + extra_offset\n",
    "    else:\n",
    "        helcorr_val = helcorr[0]\n",
    "    # Apply doopler shift to the target spectra with helcorr correction velocity \n",
    "    nflux, wlprime = pyasl.dopplerShift(wavelength, flux, helcorr_val, edgeHandling=None, fillValue=None)\n",
    "\n",
    "    print(\" RV s}ize of heliocenter correction for spectra\", helcorr_val)\n",
    "    return nflux, wlprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_ofset_for_testing = 0\n",
    "\n",
    "target_nflux, target_wlprime = barycorr_CRIRES(tellcorr_wl, tellcorr_I, tellcorr_hdr, extra_offset=manual_ofset_for_testing)\n",
    "\n",
    "ref_nflux, ref_wlprime = barycorr_CRIRES(reftellcorr_wl, reftellcorr_I, reftellcorr_hdr)\n",
    "\n",
    "# telluric line shift for masking\n",
    "target_nflux_tell, __ = barycorr_CRIRES(tellcorr_wl, tellcorr_tell, tellcorr_hdr)\n",
    "ref_nfluxtell, __ = barycorr_CRIRES(reftellcorr_wl, reftellcorr_tell, reftellcorr_hdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before and After Heliocentric Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(reftellcorr_wl, reftellcorr_I, label=\"Reference\" )\n",
    "plt.plot(tellcorr_wl, tellcorr_I, label=\"Target\")\n",
    "\n",
    "plt.title(\"Not BERV Corrected\")\n",
    "plt.xlabel(\"Wavelength(nm)\")\n",
    "\n",
    "bokeh.plotting.show(bokeh.mpl.to_bokeh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(reftellcorr_wl, ref_nflux, label=\"Reference\" )\n",
    "plt.plot(tellcorr_wl, target_nflux, label=\"Target\")\n",
    "\n",
    "plt.title(\"BERV Corrected\")\n",
    "plt.xlabel(\"Wavelength(nm)\")\n",
    "\n",
    "bokeh.plotting.show(bokeh.mpl.to_bokeh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# wavelength reference untill spectral tools is fixed \n",
    "from scipy.interpolate import interp1d\n",
    "def match_wl(wl, spec, ref_wl, method=\"scipy\", kind=\"linear\", bounds_error=False):\n",
    "    \"\"\"Interpolate Wavelengths of spectra to common WL\n",
    "    Most likely convert telluric to observed spectra wl after wl mapping performed\"\"\"\n",
    "    starttime = time.time()\n",
    "    if method == \"scipy\":\n",
    "        print(kind + \" scipy interpolation\")\n",
    "        linear_interp = interp1d(wl, spec, kind=kind, bounds_error=False)\n",
    "        new_spec = linear_interp(ref_wl)\n",
    "    elif method == \"numpy\":\n",
    "        if kind.lower() is not \"linear\":\n",
    "            print(\"Warning: Cannot do \" + kind + \" interpolation with numpy, switching to linear\" )\n",
    "        print(\"Linear numpy interpolation\")\n",
    "        new_spec = np.interp(ref_wl, wl, spec)  # 1-d peicewise linear interpolat\n",
    "    else:\n",
    "        print(\"Method was given as \" + method)\n",
    "        raise(\"Not correct interpolation method specified\")\n",
    "    print(\"Interpolation Time = \" + str(time.time() - starttime) + \" seconds\")\n",
    "\n",
    "    return new_spec  # test inperpolations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtraction !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift to the reference wavelength scale for subtraction\n",
    "### Old values\n",
    "matched_tellcorr_I = match_wl(tellcorr_wl, target_nflux, reftellcorr_wl)\n",
    "\n",
    "#subtracted_I = reftellcorr_I - matched_tellcorr_I    # O/C I think     ##### THIS was a BUG!!!\n",
    "\n",
    "## BARY Corrected values\n",
    "\n",
    "#target_nflux, target_wlprime = barycorr_CRIRES(tellcorr_wl, tellcorr_I, tellcorr_hdr, extra_offset=manual_ofset_for_testing)\n",
    "#ref_nflux, ref_wlprime = barycorr_CRIRES(reftellcorr_wl, reftellcorr_I, reftellcorr_hdr)\n",
    "#correct_match_I = match_wl(tellcorr_wl, target_nflux, reftellcorr_wl)\n",
    "\n",
    "subtracted_I = ref_nflux - matched_tellcorr_I    ##### This fixed the bug and removed stellar lines very well!!!!\n",
    "\n",
    "\n",
    "plt.plot(reftellcorr_wl, subtracted_I)\n",
    "plt.hlines(0, np.min(reftellcorr_wl), np.max(reftellcorr_wl), colors='k', linestyles='dashed', label='')\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Recovered Difference\")\n",
    "plt.title(\"Difference between {0} and {1}\".format(target, reference_target))\n",
    "bokeh.plotting.show(bokeh.mpl.to_bokeh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Include masking\n",
    "from bokeh.plotting import figure, show, output_file, gridplot\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import BoxAnnotation\n",
    "\n",
    "def bokeh_telluric_mask(fig, wl, I, mask_limit=0.9, fill_alpha=0.2, fill_color='red'):\n",
    "    \"\"\" For use with bokeh\"\"\"\n",
    "    wl_mask = I < mask_limit\n",
    "    mean_step = np.mean([wl[1]-wl[0], wl[-1]-wl[-2]])   # Average nominal step size\n",
    "    starts, ends = mask_edges(wl[wl_mask], mean_step)\n",
    "    Boxes = [BoxAnnotation(plot=fig, left=start, right= end, fill_alpha=fill_alpha, fill_color=fill_color) for start, end in zip(starts, ends)]\n",
    "    fig.renderers.extend(Boxes)\n",
    "    \n",
    "def matplotlib_telluric_mask(wl, I, mask_limit=0.9):\n",
    "    \"\"\"For use with matplotlib\"\"\"\n",
    "    wl_mask = I < mask_limit\n",
    "    mean_step = np.mean([wl[1]-wl[0], wl[-1]-wl[-2]])   # Average nominal step size\n",
    "    starts, ends = mask_edges(wl[wl_mask], mean_step)\n",
    "    [plt.axvspan(start, end, facecolor='g', alpha=0.5) for start, end in zip(starts, ends)] \n",
    "    \n",
    "def mask_edges(wl, mean_step):\n",
    "    beginings = [wav2 for wav1, wav2 in zip(wl[:-1], wl[1:]) if wav2-wav1 > 3*np.abs(mean_step)]\n",
    "    ends = [wav1 for wav1, wav2 in zip(wl[:-1], wl[1:]) if wav2-wav1 > 3*np.abs(mean_step)]\n",
    "    \n",
    "    # prepend start of first line, and append end of last line\n",
    "    beginings = [wl[0]] + beginings   # prepend starting value\n",
    "    ends = ends + [wl[-1]] # append end value\n",
    "    \n",
    "    return beginings, ends\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "\n",
    "p = figure(tools=TOOLS)\n",
    "\n",
    "p.line(reftellcorr_wl, subtracted_I)\n",
    "#plt.hlines(0, np.min(reftellcorr_wl), np.max(reftellcorr_wl), colors='k', linestyles='dashed', label='')\n",
    "\n",
    "bokeh_telluric_mask(p, reftellcorr_wl, ref_nfluxtell, mask_limit=0.95, fill_alpha=0.4, fill_color='green')\n",
    "bokeh_telluric_mask(p, reftellcorr_wl, reftellcorr_I, mask_limit=0.95, fill_alpha=0.4, fill_color='yellow')\n",
    "p.title = \"Comparison with Masks\"\n",
    "p.xaxis.axis_label = 'Wavelength'\n",
    "p.yaxis.axis_label = 'Signal'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all 3 together\n",
    "from bokeh.models import Range1d\n",
    "# Following example from http://bokeh.pydata.org/en/latest/docs/user_guide/quickstart.html\n",
    "fig_height = 250\n",
    "fig_width = 800\n",
    "\n",
    "s1 = figure(width=fig_width, height=fig_height, title=\"HD30501 Spectrum with telluric line model\")\n",
    "s1.line([np.min(tellcorr_wl), np.max(tellcorr_wl)], [1,1], color=\"black\", line_dash=\"dashed\", line_width=1)\n",
    "s1.line(tell_wl, tell_I, legend=\"TAPAS\", color=\"blue\", line_width=2)\n",
    "bokeh_telluric_mask(s1, tellcorr_wl, tellcorr_tell, mask_limit=0.95, fill_alpha=0.4, fill_color='green')\n",
    "bokeh_telluric_mask(s1, tellcorr_wl, tellcorr_I, mask_limit=0.95, fill_alpha=0.4, fill_color='yellow')\n",
    "#s1.line(gas_wl, gas_I, legend=\"ESO\", color=\"blue\", line_dash=\"dotdash\", line_width=2)\n",
    "s1.line(dracs_wl, dracs_I, legend=\"HD30501\", color=\"red\", line_dash=\"dashed\",line_width=2)\n",
    "\n",
    "#plt.plot(gas_wl, gas_I, label=\"Gasgano\")\n",
    "#plt.plot(dracs_wl, dracs_I, label=\"Dracs\")\n",
    "#plt.plot(tell_wl, tell_I, label=\"Tapas\")\n",
    "#s1.title = \"HD30501 Spectrum\"\n",
    "s1.xaxis.axis_label = 'Wavelength (nm)'\n",
    "s1.yaxis.axis_label = 'Nomalized Intensity'\n",
    "s1.legend.location = \"bottom_right\"\n",
    "s1.title_text_font_size = \"12pt\"\n",
    "s1.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "s1.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "s1.legend.border_line_color = None\n",
    "s1.set(x_range=Range1d(2111.8, 2123.6), y_range=Range1d(0.8, 1.03))  #Edit wl range\n",
    "\n",
    "# NEW: Tapas normal and H20 Scaling\n",
    "s2 = figure(width=fig_width, height=fig_height, x_range=s1.x_range, y_range=s1.y_range, \n",
    "            title=\"Telluric correction through division of the telluric line model\")\n",
    "s2.line([np.min(tellcorr_wl), np.max(tellcorr_wl)], [1,1], color=\"black\", line_dash=\"dashed\", line_width=1)\n",
    "#s2.line(tellcorr_wl, tellcorr_I, legend=\"Airmass Scaling\", color=\"blue\", line_width=2)\n",
    "#s2.line(h20tellcorr_wl, h20tellcorr_I, legend=\"H20 Scaling\", color=\"red\", line_dash=\"dashed\", line_width=2)\n",
    "s2.line(h20tellcorr_wl, h20tellcorr_I, legend=\"H20 Scaling\", color=\"blue\", line_dash=\"solid\", line_width=2)\n",
    " \n",
    "bokeh_telluric_mask(s2, tellcorr_wl, tellcorr_tell, mask_limit=0.95, fill_alpha=0.4, fill_color='green')\n",
    "bokeh_telluric_mask(s2, tellcorr_wl, tellcorr_I, mask_limit=0.95, fill_alpha=0.4, fill_color='yellow')\n",
    "\n",
    "#s2.title = \"Telluric correction by division of telluric line model\"\n",
    "s2.title_text_font_size = \"12pt\"\n",
    "s2.xaxis.axis_label = 'Wavelength (nm)'\n",
    "s2.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "s2.yaxis.axis_label = 'Normalized Intensity'\n",
    "s2.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "s2.legend.location = None\n",
    "#s2.legend.location = \"bottom_right\"\n",
    "#s2.legend.border_line_color = None\n",
    "#plt.xlabel(\"Wavelength(nm)\")\n",
    "\n",
    "# NEW: create a new plot and share only one range\n",
    "s3 = figure(width=fig_width, height=fig_height, x_range=s1.x_range, title=None)\n",
    "s3.line([np.min(reftellcorr_wl), np.max(reftellcorr_wl)], [0,0], color=\"black\", line_dash=\"dashed\", line_width=1)\n",
    "s3.line(reftellcorr_wl, subtracted_I, color=\"blue\", line_width=2)\n",
    "bokeh_telluric_mask(s3, reftellcorr_wl, ref_nfluxtell, mask_limit=0.95, fill_alpha=0.4, fill_color='green')\n",
    "bokeh_telluric_mask(s3, reftellcorr_wl, reftellcorr_I, mask_limit=0.95, fill_alpha=0.4, fill_color='yellow')\n",
    "\n",
    "s3.title = \"Subtraction of two barycentic RV corrected observations\"\n",
    "s3.title_text_font_size = \"12pt\"\n",
    "s3.xaxis.axis_label = 'Wavelength (nm)'\n",
    "s3.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "s3.yaxis.axis_label = 'Difference'\n",
    "s3.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "s3.legend.location = \"bottom_right\"\n",
    "s3.legend.border_line_color = None\n",
    "#p = gridplot([[s1],[s2],[s3]], toolbar_location=None)\n",
    "\n",
    "# show the results\n",
    "#show(p)\n",
    "\n",
    "show(column(s1, s2, s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Minimize Subtraction Residual to remove stellar line\n",
    "\n",
    "## This is unneed at present as I found a bug in my code so I was not doing the subtration with the berv corrected reference I. It is fixed now!!! 11/7/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lmfit import minimize, Parameters\n",
    "import lmfit\n",
    "manual_ofset_for_testing = -8.5\n",
    "\n",
    "\n",
    "### Fit using lmfit\n",
    "def wav_selector(wav, flux, wav_min, wav_max, verbose=False):\n",
    "    \"\"\" Faster Wavelenght selector\n",
    "    \n",
    "    If passed lists it will return lists.\n",
    "    If passed np arrays it will return arrays\n",
    "    \n",
    "    Fastest is using np.ndarrays\n",
    "    fast_wav_selector ~1000-2000 * quicker than wav_selector\n",
    "    \"\"\"\n",
    "    if isinstance(wav, list): # if passed lists\n",
    "          wav_sel = [wav_val for wav_val in wav if (wav_min < wav_val < wav_max)]\n",
    "          flux_sel = [flux_val for wav_val, flux_val in zip(wav,flux) if (wav_min < wav_val < wav_max)]\n",
    "    elif isinstance(wav, np.ndarray):\n",
    "        # Super Fast masking with numpy\n",
    "        mask = (wav > wav_min) & (wav < wav_max)\n",
    "        if verbose:\n",
    "            print(\"mask=\", mask)\n",
    "            print(\"len(mask)\", len(mask))\n",
    "            print(\"wav\", wav)\n",
    "            print(\"flux\", flux)\n",
    "        wav_sel = wav[mask]\n",
    "        flux_sel = flux[mask]\n",
    "    else:\n",
    "          raise TypeError(\"Unsupported input wav type\")\n",
    "    return [wav_sel, flux_sel]\n",
    "\n",
    "#from SpectralTools import wav_selector\n",
    "\n",
    "def stellar_line_residuals(params, target_data, reference_data):\n",
    "    # Parameters \n",
    "    rv_offset = params[\"rv_offset\"].value\n",
    "    wl_min = params[\"wl_min\"].value\n",
    "    wl_max = params[\"wl_max\"].value\n",
    "    \n",
    "    # Data\n",
    "    target_wl = target_data[0]\n",
    "    target_I = target_data[1]\n",
    "    \n",
    "    reference_wl = reference_data[0]\n",
    "    reference_I = reference_data[1]\n",
    "    \n",
    "    # dopler shift target spectrum\n",
    "    nflux, wlprime = pyasl.dopplerShift(target_wl, target_I, rv_offset, edgeHandling=None, fillValue=None)\n",
    "    \n",
    "  \n",
    "    \n",
    "    matched_wl_reference_I = match_wl(reference_wl, reference_I, target_wl)\n",
    "    \n",
    "    subtracted_I = nflux - matched_wl_reference_I\n",
    "    \n",
    "    selected_section = wav_selector(target_wl, subtracted_I, wl_min, wl_max)\n",
    " \n",
    "    # calulate aproximate area of region \n",
    "    area = np.sum(np.abs(subtracted_I[:-1] * (target_wl[1:] - target_wl[:-1])))\n",
    "    \n",
    "    return area\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "#tell_data4 = fast_wav_selector(tapas_h20_data[0], tapas_h20_data[1], 0.9995*np.min(wl4), 1.0005*np.max(wl4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up parameters \n",
    "params = Parameters()\n",
    "params.add(\"rv_offset\", value=-0)   # add min and max values ?\n",
    "params.add('wl_min', value=2116.6, vary=False)   #  hack valuses for first run. get from mask later\n",
    "params.add('wl_max', value=2117.4, vary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = minimize(stellar_line_residuals, params, args=([tellcorr_wl, target_nflux], [reftellcorr_wl, ref_nflux]))\n",
    "outreport = lmfit.fit_report(out)\n",
    "print(outreport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

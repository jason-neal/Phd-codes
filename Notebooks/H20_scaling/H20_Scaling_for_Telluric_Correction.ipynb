{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H20 Scaling for Telluric Correction\n",
    "\n",
    "Notebook for developing ideas to go into TellRemoval code.\n",
    "\n",
    "Need to apply scaling of T^x to transmision of water at full resolving power and then apply a kernal to apply in at resolution of CRIRES.\n",
    "\n",
    "Fit to the observed data (Probably with the other lines removed) to fnd the best x to apply for the correction. (Gives flatest result or zero linewidth.) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load modules and Bokeh\n",
    "# Imports from __future__ in case we're running Python 2\n",
    "from __future__ import division, print_function\n",
    "from __future__ import absolute_import, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "\n",
    "# Seaborn, useful for graphics\n",
    "import seaborn as sns\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# Import Bokeh modules for interactive plotting\n",
    "import bokeh.io\n",
    "import bokeh.mpl\n",
    "import bokeh.plotting\n",
    "\n",
    "# This enables SVG graphics inline.  There is a bug, so uncomment if it works.\n",
    "%config InlineBackend.figure_formats = {'svg',}\n",
    "\n",
    "# This enables high resolution PNGs. SVG is preferred, but has problems\n",
    "# rendering vertical and horizontal lines\n",
    "#%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# JB's favorite Seaborn settings for notebooks\n",
    "rc = {'lines.linewidth': 1, \n",
    "      'axes.labelsize': 14, \n",
    "      'axes.titlesize': 16, \n",
    "      'axes.facecolor': 'DFDFE5'}\n",
    "sns.set_context('notebook', rc=rc)\n",
    "sns.set_style('darkgrid', rc=rc)\n",
    "\n",
    "# Set up Bokeh for inline viewing\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Faster functions to try\n",
    "def fast_wav_selector(wav, flux, wav_min, wav_max, verbose=False):\n",
    "    \"\"\" Faster Wavelenght selector\n",
    "    \n",
    "    If passed lists it will return lists.\n",
    "    If passed np arrays it will return arrays\n",
    "    \n",
    "    Fastest is using np.ndarrays\n",
    "    fast_wav_selector ~1000-2000 * quicker than wav_selector\n",
    "    \"\"\"\n",
    "    if isinstance(wav, list): # if passed lists\n",
    "          wav_sel = [wav_val for wav_val in wav if (wav_min < wav_val < wav_max)]\n",
    "          flux_sel = [flux_val for wav_val, flux_val in zip(wav,flux) if (wav_min < wav_val < wav_max)]\n",
    "    elif isinstance(wav, np.ndarray):\n",
    "        # Super Fast masking with numpy\n",
    "        mask = (wav > wav_min) & (wav < wav_max)\n",
    "        if verbose:\n",
    "            print(\"mask=\", mask)\n",
    "            print(\"len(mask)\", len(mask))\n",
    "            print(\"wav\", wav)\n",
    "            print(\"flux\", flux)\n",
    "        wav_sel = wav[mask]\n",
    "        flux_sel = flux[mask]\n",
    "    else:\n",
    "          raise TypeError(\"Unsupported input wav type\")\n",
    "    return [wav_sel, flux_sel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Observed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to update these to the vacuum with no berv corrections\n",
    "chip1 = \"CRIRE.2012-04-07T00-08-29.976_1.nod.ms.norm.sum.wavecal.fits\"\n",
    "chip2 = \"CRIRE.2012-04-07T00-08-29.976_2.nod.ms.norm.sum.wavecal.fits\"\n",
    "chip3 = \"CRIRE.2012-04-07T00-08-29.976_3.nod.ms.norm.sum.wavecal.fits\"\n",
    "chip4 = \"CRIRE.2012-04-07T00-08-29.976_4.nod.ms.norm.sum.wavecal.fits\" \n",
    "\n",
    "Obs1 = fits.getdata(chip1) \n",
    "hdr1 = fits.getheader(chip1) \n",
    "Obs2 = fits.getdata(chip2) \n",
    "hdr2 = fits.getheader(chip2) \n",
    "Obs3 = fits.getdata(chip3) \n",
    "hdr3 = fits.getheader(chip3) \n",
    "Obs4 = fits.getdata(chip4) \n",
    "hdr4 = fits.getheader(chip4) \n",
    "\n",
    "print(\"Column names = {}\".format(Obs1.columns.names))\n",
    "wl1 = Obs1[\"Wavelength\"]\n",
    "I1_uncorr = Obs1[\"Extracted_DRACS\"]\n",
    "\n",
    "wl2 = Obs2[\"Wavelength\"]\n",
    "I2_uncorr = Obs2[\"Extracted_DRACS\"]\n",
    "\n",
    "wl3 = Obs3[\"Wavelength\"]\n",
    "I3_uncorr = Obs3[\"Extracted_DRACS\"]\n",
    "\n",
    "wl4 = Obs4[\"Wavelength\"]\n",
    "I4_uncorr = Obs4[\"Extracted_DRACS\"]\n",
    "\n",
    "start_airmass = hdr1[\"HIERARCH ESO TEL AIRM START\"]\n",
    "end_airmass = hdr1[\"HIERARCH ESO TEL AIRM END\"]\n",
    "obs_airmass = (start_airmass + end_airmass) / 2\n",
    "print(\"Data from Detectors is now loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Rough berv correction until input calibrated file is calibrated with non berv tapas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wl1 = wl1-.5   #including rough berv correction\n",
    "wl2 = wl2-.54  #including rough berv correction\n",
    "wl3 = wl3-.55  #including rough berv correction\n",
    "wl4 = wl4-.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the tapas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Obtain_Telluric as obt\n",
    "tapas_all = \"tapas_2012-04-07T00-24-03_ReqId_10_R-50000_sratio-10_barydone-NO.ipac\"\n",
    "tapas_h20 = \"tapas_2012-04-07T00-24-03_ReqId_12_No_Ifunction_barydone-NO.ipac\"\n",
    "tapas_not_h20 = \"tapas_2012-04-07T00-24-03_ReqId_18_R-50000_sratio-10_barydone-NO.ipac\"\n",
    "\n",
    "tapas_all_data, tapas_all_hdr = obt.load_telluric(\"\", tapas_all)\n",
    "tapas_all_airmass = float(tapas_all_hdr[\"airmass\"])\n",
    "\n",
    "print(\"Telluric Airmass \", tapas_all_airmass)\n",
    "tapas_all_respower = int(float((tapas_all_hdr[\"respower\"])))\n",
    "print(\"Telluric Resolution Power =\", tapas_all_respower)\n",
    "\n",
    "tapas_h20_data, tapas_h20_hdr = obt.load_telluric(\"\", tapas_h20)\n",
    "tapas_h20_airmass = float(tapas_h20_hdr[\"airmass\"])\n",
    "\n",
    "print(\"Telluric Airmass \", tapas_h20_airmass)\n",
    "try:\n",
    "    tapas_h20_respower = int(float((tapas_h20_hdr[\"respower\"])))\n",
    "except:\n",
    "    tapas_h20_respower = \"Nan\"\n",
    "print(\"Telluric Resolution Power =\", tapas_h20_respower)\n",
    "\n",
    "tapas_not_h20_data, tapas_not_h20_hdr = obt.load_telluric(\"\", tapas_not_h20)\n",
    "tapas_not_h20_airmass = float(tapas_not_h20_hdr[\"airmass\"])\n",
    "\n",
    "print(\"Telluric Airmass \", tapas_not_h20_airmass)\n",
    "tapas_not_h20_respower = int(float((tapas_not_h20_hdr[\"respower\"])))\n",
    "print(\"Telluric Resolution Power =\", tapas_not_h20_respower)\n",
    "    \n",
    "#print(tapas_all_hdr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(tapas_h20_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data\n",
    "Including the 3 tapas models to show they align well and are consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(wl1, I1_uncorr, 'b') #including rough berv correction\n",
    "plt.plot(wl2, I2_uncorr, 'b') #including rough berv correction\n",
    "plt.plot(wl3, I3_uncorr, 'b') #including rough berv correction\n",
    "plt.plot(wl4, I4_uncorr, 'b') #including rough berv correction\n",
    "plt.plot(tapas_h20_data[0], tapas_h20_data[1], \"--k\", label=\"H20\")\n",
    "plt.plot(tapas_all_data[0], tapas_all_data[1], \"-r\", label=\"all\")\n",
    "plt.plot(tapas_not_h20_data[0], tapas_not_h20_data[1], \"-.g\", label=\"Not H20\")\n",
    "\n",
    "#plt.legend()\n",
    "\n",
    "# Make it interactive with Bokeh\n",
    "bokeh.plotting.show(bokeh.mpl.to_bokeh())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-H20 lines\n",
    "(Use telluric removal modules)\n",
    "And plot the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from TellRemoval import divide_spectra, airmass_scaling, telluric_correct, match_wl\n",
    "\n",
    "def correction(wl_obs, spec_obs, wl_tell, spec_tell, obs_airmass, tell_airmass, kind=\"linear\", method=\"scipy\"):\n",
    "    interped_tell = match_wl(wl_tell, spec_tell, wl_obs)\n",
    "    scaled_tell = airmass_scaling(interped_tell, tell_airmass, obs_airmass)\n",
    "    corr_spec = divide_spectra(spec_obs, scaled_tell)                        # Divide by scaled telluric spectra\n",
    "    return corr_spec\n",
    "    \n",
    "def faster_correction(wl_obs, spec_obs, wl_tell, spec_tell, obs_airmass, tell_airmass, kind=\"linear\", method=\"scipy\"):\n",
    "    interped_tell = match_wl(wl_tell, spec_tell, wl_obs)\n",
    "    scaled_tell = airmass_scaling(interped_tell, tell_airmass, obs_airmass)\n",
    "    corr_spec = divide_spectra(spec_obs, scaled_tell)                        # Divide by scaled telluric spectra\n",
    "    return corr_spec\n",
    "#def telluric_correct(wl_obs, spec_obs, wl_tell, spec_tell, obs_airmass, tell_airmass, kind=\"linear\", method=\"scipy\"):\n",
    "#    return Corrections, Correction_tells, Correction_Bs, Correction_labels\n",
    "\n",
    "# Corrections, Correction_tells, Correction_Bs, Correction_labels = telluric_correct(wl2, I2_uncorr, tapas_not_h20[0], tapas_not_h20[1], obs_airmass, tapas_not_h20_airmass) \n",
    "# Getting zero division error from this function so will try it again from te functions here\n",
    "tell_airmass = tapas_not_h20_airmass\n",
    "\n",
    "I1_not_h20_corr = correction(wl1, I1_uncorr, tapas_not_h20_data[0], tapas_not_h20_data[1], obs_airmass, tapas_not_h20_airmass, kind=\"linear\", method=\"scipy\")\n",
    "I2_not_h20_corr = correction(wl2, I2_uncorr, tapas_not_h20_data[0], tapas_not_h20_data[1], obs_airmass, tapas_not_h20_airmass, kind=\"linear\", method=\"scipy\")\n",
    "I3_not_h20_corr = correction(wl3, I3_uncorr, tapas_not_h20_data[0], tapas_not_h20_data[1], obs_airmass, tapas_not_h20_airmass, kind=\"linear\", method=\"scipy\")\n",
    "I4_not_h20_corr = correction(wl4, I4_uncorr, tapas_not_h20_data[0], tapas_not_h20_data[1], obs_airmass, tapas_not_h20_airmass, kind=\"linear\", method=\"scipy\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to remove print statement from iterpolation timing to run this again.\n",
    "#%timeit correction(wl1, I1_uncorr, tapas_not_h20_data[0], tapas_not_h20_data[1], obs_airmass, tapas_not_h20_airmass, kind=\"linear\", method=\"scipy\")\n",
    "\n",
    "\n",
    "# not yet any changes to mkae faster.\n",
    "#%timeit faster_correction(wl1, I1_uncorr, tapas_not_h20_data[0], tapas_not_h20_data[1], obs_airmass, tapas_not_h20_airmass, kind=\"linear\", method=\"scipy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot not h20 correction\n",
    "\n",
    "plt.plot(wl1, I1_uncorr, \"b\")\n",
    "plt.plot(wl2, I2_uncorr, \"b\")\n",
    "plt.plot(wl3, I3_uncorr, \"b\")\n",
    "plt.plot(wl4, I4_uncorr, \"b\")\n",
    "plt.plot(wl1, I1_not_h20_corr, \"r\")\n",
    "plt.plot(wl2, I2_not_h20_corr, \"r\")\n",
    "plt.plot(wl3, I3_not_h20_corr, \"r\")\n",
    "plt.plot(wl4, I4_not_h20_corr, \"r\")\n",
    "plt.plot(tapas_not_h20_data[0], tapas_not_h20_data[1], \"k\")\n",
    "# Make it interactive with Bokeh\n",
    "bokeh.plotting.show(bokeh.mpl.to_bokeh())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Convolution from Pyastronomy\n",
    "This function broadens a spectrum assuming a Gaussian kernel. The width of the kernel is determined by the resolution. In particular, the function will determine the mean wavelength and set the Full Width at Half Maximum (FWHM) of the Gaussian to (mean wavelength)/resolution.\n",
    "Parameters :    \n",
    "wvl : array\n",
    "    The wavelength\n",
    "\n",
    "flux : array\n",
    "    The spectrum\n",
    "\n",
    "resolution : int\n",
    "    The spectral resolution.\n",
    "    \n",
    "\n",
    "The Pyastronomy convolution needs equidistant points to work. This involves performing an interpolation. We prefer not to use this method as it losses information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just to my CRIRES range \n",
    "from PyAstronomy import pyasl    \n",
    "R = 50000  \n",
    "\n",
    "chipmin = float(hdr1[\"HIERARCH ESO INS WLEN STRT1\"])  # Wavelength start on detector [nm]\n",
    "chipmax = float(hdr1[\"HIERARCH ESO INS WLEN END4\"])   # Wavelength end on detector [nm]\n",
    "wav_chip, flux_chip = fast_wav_selector(tapas_h20_data[0], tapas_h20_data[1], chipmin, chipmax)\n",
    "\n",
    "FWHM_min = wav_chip[0]/R    #FWHM at the extremes of vector\n",
    "FWHM_max = wav_chip[-1]/R   \n",
    "\n",
    "print(\"Min FWHM\", FWHM_min)\n",
    "print(\"Max FWHM\", FWHM_max)\n",
    "\n",
    "# pyasl needs equidistant wavelenghts \n",
    "\n",
    "from Find_gcdt import gcdt\n",
    "greatest_common_divisor = gcdt(wav_chip, 4)\n",
    "print(\"Found divisor = \", greatest_common_divisor)\n",
    "steps = (wav_chip[-1] - wav_chip[0])/greatest_common_divisor\n",
    "print(\"NUmber of steps =\", steps)\n",
    "\n",
    "new_wav = np.linspace(wav_chip[0], wav_chip[-1], num=steps, endpoint=True)\n",
    "\n",
    "# Inperolate_to_new_wave  \n",
    "new_flux = match_wl(wav_chip, flux_chip, new_wav)\n",
    "print(\"length of new flux\", len(new_flux))\n",
    "\n",
    "diffs = np.diff(wav_chip)\n",
    "print(\"First Diff={}, last diff={}\".format(diffs[0], diffs[-1]))\n",
    "\n",
    "data_step = 2 * (wav_chip[-1] - wav_chip[0])/np.min(diffs) \n",
    "new_diff_wav = np.linspace(wav_chip[0], wav_chip[-1], num=data_step, endpoint=True)\n",
    "\n",
    "new_diff_flux = match_wl(wav_chip, flux_chip, new_diff_wav)\n",
    "print(\"length of new flux\", len(new_diff_flux))\n",
    "\n",
    "#new_flux = np.interp(new_wav, wav_chip, flux_chip)\n",
    "\n",
    "# Prefer not to use this method\n",
    "Conv_flux_pysal = pyasl.instrBroadGaussFast(new_wav, new_flux, 50000, edgeHandling=None, fullout=False, maxsig=None)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PLot Pyasl convolution\n",
    "plt.plot(tapas_h20_data[0], tapas_h20_data[1],\"b\")\n",
    "plt.plot(new_wav,Conv_flux_pysal, \"r\")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Flux\")\n",
    "plt.title(\"Test of Pyasl convolution \\n (Used interpolation to equidistant points)\")\n",
    "#plt.show()\n",
    "# Make it interactive with Bokeh\n",
    "bokeh.plotting.show(bokeh.mpl.to_bokeh())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No interpolation convolution \n",
    "Speed up with numpy mask instead of comprehnsion list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chip version\n",
    "def chip_selector(wav, flux, chip):\n",
    "    # This uses hdr that does not live in this function !!!!!\n",
    "    chip = str(chip)\n",
    "    if(chip in [\"ALL\", \"all\", \"\",\"0\"]):\n",
    "        chipmin = float(hdr1[\"HIERARCH ESO INS WLEN STRT1\"])  # Wavelength start on detector [nm]\n",
    "        chipmax = float(hdr1[\"HIERARCH ESO INS WLEN END4\"])   # Wavelength end on detector [nm]\n",
    "        #return [wav, flux]\n",
    "    elif(chip == \"1\"):\n",
    "        chipmin = float(hdr1[\"HIERARCH ESO INS WLEN STRT1\"])  # Wavelength start on detector [nm]\n",
    "        chipmax = float(hdr1[\"HIERARCH ESO INS WLEN END1\"])   # Wavelength end on detector [nm]\n",
    "    elif(chip == \"2\"):\n",
    "        chipmin = float(hdr1[\"HIERARCH ESO INS WLEN STRT2\"])  # Wavelength start on detector [nm]\n",
    "        chipmax = float(hdr1[\"HIERARCH ESO INS WLEN END2\"])   # Wavelength end on detector [nm]\n",
    "    elif(chip == \"3\"):   \n",
    "        chipmin = float(hdr1[\"HIERARCH ESO INS WLEN STRT3\"])  # Wavelength start on detector [nm]\n",
    "        chipmax = float(hdr1[\"HIERARCH ESO INS WLEN END3\"])   # Wavelength end on detector [nm]\n",
    "    elif(chip == \"4\"):   \n",
    "        chipmin = float(hdr1[\"HIERARCH ESO INS WLEN STRT4\"])  # Wavelength start on detector [nm]\n",
    "        chipmax = float(hdr1[\"HIERARCH ESO INS WLEN END4\"])   # Wavelength end on detector [nm]\n",
    "    elif(chip == \"Joblib_small\"):   \n",
    "        chipmin = float(2118)  # Wavelength start on detector [nm]\n",
    "        chipmax = float(2119)  # Wavelength end on detector [nm]\n",
    "    elif(chip == \"Joblib_large\"):   \n",
    "        chipmin = float(2149)  # Wavelength start on detector [nm]\n",
    "        chipmax = float(2157)  # Wavelength end on detector [nm]\n",
    "    else:\n",
    "        print(\"Unrecognized chip tag.\")\n",
    "        exit()\n",
    "    \n",
    "    #select values form the chip  \n",
    "    wav_chip, flux_chip = fast_wav_selector(wav, flux, chipmin, chipmax)\n",
    "    \n",
    "    return [wav_chip, flux_chip]\n",
    "\n",
    "\n",
    "def convolution_nir_chip(wav, flux, chip, R, FWHM_lim=5.0, plot=True, verbose=True):\n",
    "    \"\"\"Convolution code adapted from pedros code and speed up with np mask logic\"\"\"\n",
    "    \"\"\" this version keeps the chip values from chip selector\"\"\"\n",
    "    #print(\"types\", type(wav), type(flux), type(chip))\n",
    "    #print(\"lengths\", len(wav), len(flux), len(chip))\n",
    "    \n",
    "    # CRIRES HDR vals for chip limits don't match well with calibrated values (get interpolation out of range error)\n",
    "    # So will use limits from the obs data instead \n",
    "    wav_chip, flux_chip = chip_selector(wav, flux, chip)\n",
    "    #wav_chip, flux_chip = fast_wav_selector(wav, flux, chip_limits[0], chip_limits[1])\n",
    "    #we need to calculate the FWHM at this value in order to set the starting point for the convolution\n",
    "    \n",
    "    FWHM_min = wav_chip[0]/R    #FWHM at the extremes of vector\n",
    "    FWHM_max = wav_chip[-1]/R       \n",
    "    \n",
    "    #wide wavelength bin for the resolution_convolution\n",
    "    wav_extended, flux_extended = fast_wav_selector(wav, flux, wav_chip[0]-FWHM_lim*FWHM_min, wav_chip[-1]+FWHM_lim*FWHM_max, verbose=False) \n",
    "    # isinstance check is ~100*faster then arraying the array again.\n",
    "    if not isinstance(wav_extended, np.ndarray):\n",
    "        wav_extended = np.array(wav_extended, dtype=\"float64\") \n",
    "    if not isinstance(flux_extended, np.ndarray):\n",
    "        flux_extended = np.array(flux_extended, dtype=\"float64\")\n",
    "    \n",
    "    print(\"Starting the Resolution convolution...\")\n",
    "    # Predefine np array space\n",
    "    flux_conv_res = np.empty_like(wav_chip, dtype=\"float64\")\n",
    "    counter = 0 \n",
    "    base_val = len(wav_chip)//20   # Adjust here to change % between reports\n",
    "    \n",
    "    for n, wav in enumerate(wav_chip):\n",
    "        # put value directly into the array\n",
    "        flux_conv_res[n] = fast_convolve(wav, R, wav_extended, flux_extended, FWHM_lim)\n",
    "        if(n%base_val== 0) and verbose:\n",
    "            counter = counter+5\n",
    "            print(\"Resolution Convolution at {}%%...\".format(counter))\n",
    "    \n",
    "    #if not isinstance(flux_conv_res, np.ndarray):\n",
    "    #    flux_conv_res = np.array(flux_conv_res, dtype=\"float64\")\n",
    "        \n",
    "    print(\"Done.\\n\")\n",
    "    \n",
    "    if(plot):\n",
    "        fig=plt.figure(1)\n",
    "        plt.xlabel(r\"wavelength [ $\\mu$m ])\")\n",
    "        plt.ylabel(r\"flux [counts] \")\n",
    "        plt.plot(wav_chip, flux_chip/np.max(flux_chip), color ='k', linestyle=\"-\", label=\"Original spectra\")\n",
    "        plt.plot(wav_chip, flux_conv_res/np.max(flux_conv_res), color ='b', linestyle=\"-\", label=\"Spectrum observed at and R=%d .\" % (R))\n",
    "        plt.legend(loc='best')\n",
    "        plt.show() \n",
    "    return [wav_chip, flux_conv_res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convole instrument profile function:\n",
    "To use inside fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## USEFUL functions from pedros code:\n",
    "# This is pedros slow selector\n",
    "#def wav_selector(wav, flux, wav_min, wav_max):\n",
    "#    \"\"\"\n",
    "#    function that returns wavelength and flux withn a giving range\n",
    "#    \"\"\"    \n",
    "#    wav_sel = np.array([value for value in wav if(wav_min < value < wav_max)], dtype=\"float64\")\n",
    "#    flux_sel = np.array([value[1] for value in zip(wav,flux) if(wav_min < value[0] < wav_max)], dtype=\"float64\")\n",
    "#    \n",
    "#    return [wav_sel, flux_sel]\n",
    "\n",
    "\n",
    "def unitary_Gauss(x, center, FWHM):\n",
    "    \"\"\"\n",
    "    Gaussian_function of area=1\n",
    "\t\n",
    "\tp[0] = A;\n",
    "\tp[1] = mean;\n",
    "\tp[2] = FWHM;\n",
    "    \"\"\"\n",
    "    \n",
    "    sigma = np.abs(FWHM) /( 2 * np.sqrt(2 * np.log(2)) );\n",
    "    Amp = 1.0 / (sigma*np.sqrt(2*np.pi))\n",
    "    tau = -((x - center)**2) / (2*(sigma**2))\n",
    "    result = Amp * np.exp( tau );\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fast_convolve(wav_val, R, wav_extended, flux_extended, FWHM_lim):\n",
    "    \"\"\"IP convolution multiplication step for a single wavelength value\"\"\"\n",
    "    FWHM = wav_val/R\n",
    "    \n",
    "    index_mask = (wav_extended > (wav_val - FWHM_lim*FWHM)) &  (wav_extended < (wav_val + FWHM_lim*FWHM))\n",
    "    \n",
    "    flux_2convolve = flux_extended[index_mask]\n",
    "    IP = unitary_Gauss(wav_extended[index_mask], wav_val, FWHM)\n",
    "    \n",
    "    sum_val = np.sum(IP*flux_2convolve) \n",
    "    unitary_val = np.sum(IP*np.ones_like(flux_2convolve))  # Effect of convolution onUnitary. For changing number of points\n",
    "        \n",
    "    return sum_val/unitary_val\n",
    "\n",
    "def convolution_nir(wav, flux, chip_limits, R, FWHM_lim=5.0, plot=True, verbose=True):\n",
    "    \"\"\"Convolution code adapted from pedros code and speed up with np mask logic\"\"\"\n",
    "    \n",
    "    #print(\"types\", type(wav), type(flux), type(chip))\n",
    "    #print(\"lengths\", len(wav), len(flux), len(chip))\n",
    "    \n",
    "    # CRIRES HDR vals for chip limits don't match well with calibrated values (get interpolation out of range error)\n",
    "    # So will use limits from the obs data instead \n",
    "    #wav_chip, flux_chip = chip_selector(wav, flux, chip)\n",
    "    wav_chip, flux_chip = fast_wav_selector(wav, flux, chip_limits[0], chip_limits[1])\n",
    "    #we need to calculate the FWHM at this value in order to set the starting point for the convolution\n",
    "    \n",
    "    FWHM_min = wav_chip[0]/R    #FWHM at the extremes of vector\n",
    "    FWHM_max = wav_chip[-1]/R       \n",
    "    \n",
    "    #wide wavelength bin for the resolution_convolution\n",
    "    wav_extended, flux_extended = fast_wav_selector(wav, flux, wav_chip[0]-FWHM_lim*FWHM_min, wav_chip[-1]+FWHM_lim*FWHM_max, verbose=False) \n",
    "    # isinstance check is ~100*faster then arraying the array again.\n",
    "    if not isinstance(wav_extended, np.ndarray):\n",
    "        wav_extended = np.array(wav_extended, dtype=\"float64\") \n",
    "    if not isinstance(flux_extended, np.ndarray):\n",
    "        flux_extended = np.array(flux_extended, dtype=\"float64\")\n",
    "    \n",
    "    print(\"Starting the Resolution convolution...\")\n",
    "    # Predefine np array space\n",
    "    flux_conv_res = np.empty_like(wav_chip, dtype=\"float64\")\n",
    "    counter = 0 \n",
    "    base_val = len(wav_chip)//20   # Adjust here to change % between reports\n",
    "    \n",
    "    for n, wav in enumerate(wav_chip):\n",
    "        # put value directly into the array\n",
    "        flux_conv_res[n] = fast_convolve(wav, R, wav_extended, flux_extended, FWHM_lim)\n",
    "        if(n%base_val== 0) and verbose:\n",
    "            counter = counter+5\n",
    "            print(\"Resolution Convolution at {}%%...\".format(counter))\n",
    "    \n",
    "    #if not isinstance(flux_conv_res, np.ndarray):\n",
    "    #    flux_conv_res = np.array(flux_conv_res, dtype=\"float64\")\n",
    "        \n",
    "    print(\"Done.\\n\")\n",
    "    \n",
    "    if(plot):\n",
    "        fig=plt.figure(1)\n",
    "        plt.xlabel(r\"wavelength [ $\\mu$m ])\")\n",
    "        plt.ylabel(r\"flux [counts] \")\n",
    "        plt.plot(wav_chip, flux_chip/np.max(flux_chip), color ='k', linestyle=\"-\", label=\"Original spectra\")\n",
    "        plt.plot(wav_chip, flux_conv_res/np.max(flux_conv_res), color ='b', linestyle=\"-\", label=\"Spectrum observed at and R=%d .\" % (R))\n",
    "        plt.legend(loc='best')\n",
    "        plt.show() \n",
    "    return [wav_chip, flux_conv_res]\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test convolution runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 10 seconds per loop for chip \"1\" and plotting   (down from 900s)\n",
    "#timeit x, y = convolution_nir(tapas_h20_data[0], tapas_h20_data[1], \"1\", 50000, FWHM_lim=5.0, plot=True)\n",
    "limits = [2124,2136]\n",
    "x, y = convolution_nir(tapas_h20_data[0], tapas_h20_data[1], limits, 50000, FWHM_lim=5.0, plot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Profile to see what takes the most time\n",
    "%prun x, y = convolution_nir(tapas_h20_data[0], tapas_h20_data[1], limits, 50000, FWHM_lim=5.0, plot=False)\n",
    "# Answer is the IP calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time on work comp - 188.6781919 s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(tapas_h20_data[0], tapas_h20_data[1],\"b\")\n",
    "plt.plot(x, y, \"r\")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Flux\")\n",
    "plt.title(\"Test of convolution\")\n",
    "#plt.show()\n",
    "# Make it interactive with Bokeh\n",
    "bokeh.plotting.show(bokeh.mpl.to_bokeh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit H20 Scaling Power\n",
    "Does each chip need a differnet scaling power?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lmfit import minimize, Parameters\n",
    "import lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "#from TellRemoval import divide_spectra, airmass_scaling, telluric_correct, match_wl\n",
    "def match_wl(wl, spec, ref_wl, method=\"scipy\", kind=\"linear\"):\n",
    "    \"\"\"Interpolate Wavelengths of spectra to common WL\n",
    "    Most likely convert telluric to observed spectra wl after wl mapping performed\"\"\"\n",
    "    #starttime = time.time()\n",
    "    if method == \"scipy\":\n",
    "        #print(kind + \" scipy interpolation\")\n",
    "        linear_interp = interp1d(wl, spec, kind=kind)\n",
    "        new_spec = linear_interp(ref_wl)\n",
    "    elif method == \"numpy\":\n",
    "        if kind.lower() is not \"linear\":\n",
    "            print(\"Warning: Cannot do \" + kind + \" interpolation with numpy, switching to linear\" )\n",
    "        #print(\"Linear numpy interpolation\")\n",
    "        new_spec = np.interp(ref_wl, wl, spec)  # 1-d peicewise linear interpolat\n",
    "    else:\n",
    "        print(\"Method was given as \" + method)\n",
    "        raise(\"Not correct interpolation method specified\")\n",
    "    #print(\"Interpolation Time = \" + str(time.time() - starttime) + \" seconds\")\n",
    "\n",
    "    return new_spec  # test inperpolations \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Fit using lmfit\n",
    "\n",
    "def h20_residual(params, obs_data, telluric_data):\n",
    "    # Parameters \n",
    "    ScaleFactor = params[\"ScaleFactor\"].value\n",
    "    R = params[\"R\"].value\n",
    "    FWHM_lim = params[\"FWHM_lim\"].value\n",
    "    #n_jobs = params[\"n_jobs\"].value  # parallel implementaiton\n",
    "    #chip_select = params[\"chip_select\"].value\n",
    "    verbose = params[\"verbose\"].value\n",
    "    \n",
    "    # Data\n",
    "    obs_wl = obs_data[0]\n",
    "    obs_I = obs_data[1]\n",
    "    telluric_wl = telluric_data[0]\n",
    "    telluric_I = telluric_data[1]\n",
    "    \n",
    "    # Telluric scaling T ** x\n",
    "    scaled_telluric_I = telluric_I ** ScaleFactor\n",
    "    \n",
    "    # smallest wl step in telluric wl\n",
    "    min_dwl = np.min(telluric_wl[1:]-telluric_wl[:-1])\n",
    "    # Make sure atleast 1 telluric value is outside wl range of observation for interpoltion later \n",
    "    chip_limits = [obs_wl[0]-2*min_dwl, obs_wl[-1]+2*min_dwl] \n",
    "    # Convolution\n",
    "    #def convolution_nir(wav, flux, chip, R, FWHM_lim=5.0, plot=True):\n",
    "    #    return [wav_chip, flux_conv_res]\n",
    "    conv_tell_wl, conv_tell_I = convolution_nir(telluric_wl, scaled_telluric_I, chip_limits,\n",
    "                                                R, FWHM_lim=FWHM_lim, plot=False, verbose=verbose)\n",
    "    \n",
    "    print(\"Obs wl- Min \", np.min(obs_wl),\" Max \", np.max(obs_wl))\n",
    "    print(\"Input telluic wl- Min \", np.min(telluric_wl),\" Max \", np.max(telluric_wl))\n",
    "    print(\"conv tell wl- Min \", np.min(conv_tell_wl),\" Max \", np.max(conv_tell_wl))\n",
    "  \n",
    "    \n",
    "    interped_conv_tell = match_wl(conv_tell_wl, conv_tell_I, obs_wl)\n",
    "    print(\"Convolution and interpolation inside residual function was done\")\n",
    "    \n",
    "    return 1 - (obs_I / interped_conv_tell) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up parameters \n",
    "params = Parameters()\n",
    "params.add('ScaleFactor', value=1)   # add min and max values ?\n",
    "params.add('R', value=50000, vary=False)\n",
    "params.add('FWHM_lim', value=5, vary=False)\n",
    "#params.add('n_jobs', value=-1, vary=False)\n",
    "#params.add('chip_select', value=2, vary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wl2, I2_uncorr\n",
    "# wl2, I2_not_h20_corr\n",
    "\n",
    "# Sliced to wavelength measurement of detector\n",
    "#tell_data1 = fast_wav_selector(tapas_h20_data[0], tapas_h20_data[1], np.min(wl1), np.max(wl1))\n",
    "tell_data2 = fast_wav_selector(tapas_h20_data[0], tapas_h20_data[1], 0.9995*np.min(wl2), 1.0005*np.max(wl2))\n",
    "#tell_data3 = fast_wav_selector(tapas_h20_data[0], tapas_h20_data[1], np.min(wl3), np.max(wl3))\n",
    "#tell_data4 = fast_wav_selector(tapas_h20_data[0], tapas_h20_data[1], np.min(wl4), np.max(wl4))\n",
    "\n",
    "\n",
    "print(\"Obs wl- Min \", np.min(wl2),\" Max \", np.max(wl2))\n",
    "print(\"0.9995*Obs wl min\", 0.9995*np.min(wl2),\" 1.005*Obs wl max\", 1.005*np.max(wl2))\n",
    "print(\"Input telluic wl- Min \", np.min(tell_data2[0]),\" Max \", np.max(tell_data2[0]))\n",
    "#print(\"conv tell wl- Min \", np.min(conv_tell_wl),\" Max \", np.max(conv_tell_wl))\n",
    "        \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1.002*2137\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Peform minimization\n",
    "import time\n",
    "params.add(\"verbose\", value=False, vary=False)\n",
    "start = time.time()\n",
    "out = minimize(h20_residual, params, args=([wl2, I2_not_h20_corr], tell_data2))\n",
    "print(\"Time of fit =\", time.time()-start)\n",
    "outreport = lmfit.fit_report(out)\n",
    "print(outreport)\n",
    "\n",
    "# 74 seconds for one detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Best_factor = out.params[\"ScaleFactor\"].value\n",
    "print(Best_factor)\n",
    "\n",
    "# Telluric scaling T ** x\n",
    "Scalled_tell2 = [tell_data2[0], tell_data2[1]**Best_factor]\n",
    "\n",
    "# smallest wl step in telluric wl\n",
    "min_dwl = np.min(Scalled_tell2[0][1:]-Scalled_tell2[0][:-1])\n",
    "# Make sure atleast 1 telluric value is outside wl range of observation for interpoltion later \n",
    "chip_limits = [wl2[0]-2*min_dwl, wl2[-1]+2*min_dwl] \n",
    "# Convolution\n",
    "#def convolution_nir(wav, flux, chip, R, FWHM_lim=5.0, plot=True):\n",
    "#    return [wav_chip, flux_conv_res]\n",
    "Conv_Scalled_tell2 = convolution_nir(Scalled_tell2[0], Scalled_tell2[1], chip_limits,\n",
    "                                                50000, FWHM_lim=5, plot=False, verbose=True)\n",
    "Just_convolved_tell2 = convolution_nir(tell_data2[0], tell_data2[1], chip_limits,\n",
    "                                                50000, FWHM_lim=5, plot=False, verbose=True)\n",
    "\n",
    "Interped_conv_tell2 = [wl2, match_wl(Conv_Scalled_tell2[0], Conv_Scalled_tell2[1], wl2)]\n",
    "Interped_just_conv_tell2 = [wl2, match_wl(Conv_Scalled_tell2[0], Just_convolved_tell2, wl2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot scalled telluric and convolved value\n",
    "plt.plot(wl2, I2_not_h20_corr, 'k', label=\"Obs\")\n",
    "plt.plot(tell_data2[0], tell_data2[1], 'b', label=\"Original tell\")\n",
    "plt.plot(Scalled_tell2[0], Scalled_tell2[1], 'g', label=\"Scaled\")\n",
    "plt.plot(Interped_conv_tell2[0], Interped_conv_tell2[1], 'r', label=\"Scaled +convolved\")\n",
    "plt.plot(Interped_conv_tell2[0], Interped_just_conv_tell2[1], 'm', label=\"Just convolved\")\n",
    "#plt.legend()\n",
    "\n",
    "# Make it interactive with Bokeh\n",
    "bokeh.plotting.show(bokeh.mpl.to_bokeh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot corrected value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Time the Peform minimization\n",
    "out = minimize(h20_residual, params, args=([wl2, I2_not_h20_corr], tell_data2))\n",
    "outreport = lmfit.fit_report(out)\n",
    "print(outreport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1.9*1000/.831\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply correction with best scaling power:\n",
    "\n",
    "And plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARALLELISATION CODES /ATTEMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def convolve(wav, R, wav_extended, flux_extended, FWHM_lim):\n",
    "        # select all values such that they are within the FWHM limits\n",
    "        FWHM = wav/R\n",
    "        indexes = [ i for i in range(len(wav_extended)) if ((wav - FWHM_lim*FWHM) < wav_extended[i] < (wav + FWHM_lim*FWHM))]\n",
    "        flux_2convolve = flux_extended[indexes[0]:indexes[-1]+1]\n",
    "        IP = unitary_Gauss(wav_extended[indexes[0]:indexes[-1]+1], wav, FWHM)\n",
    "        val = np.sum(IP*flux_2convolve) \n",
    "        unitary_val = np.sum(IP*np.ones_like(flux_2convolve))  # Effect of convolution onUnitary. For changing number of points\n",
    "        return val/unitary_val\n",
    "    \n",
    "def fast_convolve(wav, R, wav_extended, flux_extended, FWHM_lim):\n",
    "    FWHM = wav/R\n",
    "    \n",
    "    index_mask = (wav_extended > (wav - FWHM_lim*FWHM)) &  (wav_extended < (wav + FWHM_lim*FWHM))\n",
    "    \n",
    "    flux_2convolve = flux_extended[index_mask]\n",
    "    IP = unitary_Gauss(wav_extended[index_mask], wav, FWHM)\n",
    "    \n",
    "    val = np.sum(IP*flux_2convolve) \n",
    "    unitary_val = np.sum(IP*np.ones_like(flux_2convolve))  # Effect of convolution onUnitary. For changing number of points\n",
    "        \n",
    "    return val/unitary_val\n",
    "    \n",
    "def parallel_convolution(wav, flux, chip, R, FWHM_lim=5.0, n_jobs=-1, parallel_workers=None):\n",
    "    \"\"\"Convolution code adapted from pedros code\"\"\"\n",
    "    \n",
    "    wav_chip, flux_chip = chip_selector(wav, flux, chip)\n",
    "    #we need to calculate the FWHM at this value in order to set the starting point for the convolution\n",
    "    \n",
    "    #print(wav_chip)\n",
    "    #print(flux_chip)\n",
    "    FWHM_min = wav_chip[0]/R    #FWHM at the extremes of vector\n",
    "    FWHM_max = wav_chip[-1]/R       \n",
    "    \n",
    "    #wide wavelength bin for the resolution_convolution\n",
    "    wav_extended, flux_extended = fast_wav_selector(wav, flux, wav_chip[0]-FWHM_lim*FWHM_min, wav_chip[-1]+FWHM_lim*FWHM_max) \n",
    "    wav_extended = np.array(wav_extended, dtype=\"float64\")\n",
    "    flux_extended = np.array(flux_extended, dtype=\"float64\")\n",
    "    \n",
    "    print(\"Starting the Parallel Resolution convolution...\")\n",
    "    \n",
    "    flux_conv_res = []\n",
    "    counter = 0    \n",
    "    # lambda doesnt work in parallel - it doesn't pickel \n",
    "    #lambda_funct = lambda x: convolve(x,R,wav_extended, flux_extended,FWHM_lim)\n",
    "    #parallel_result = Parallel(n_jobs=-1)(delayed(lambda_funct)(wav) for wav in wav_chip)\n",
    "    \n",
    "    #for wav in wav_chip:\n",
    "    #    a = convolve(wav,R,wav_extended, flux_extended,FWHM_lim)\n",
    "    #    a = lambda_funct(wav)\n",
    "    #    flux_conv_res.append(a)\n",
    "    #    if(len(flux_conv_res)%(len(wav_chip)//100 ) == 0):\n",
    "    #        counter = counter+1\n",
    "    #        print(\"Resolution Convolution at {}%%...\".format(counter))\n",
    "    #flux_conv_res = np.array(flux_conv_res, dtype=\"float64\")\n",
    "    \n",
    "    \n",
    "    # select all values such that they are within the FWHM limits\n",
    "    #   FWHM = wav/R\n",
    "    #   indexes = [ i for i in range(len(wav_extended)) if ((wav - FWHM_lim*FWHM) < wav_extended[i] < (wav + FWHM_lim*FWHM))]\n",
    "    #   flux_2convolve = flux_extended[indexes[0]:indexes[-1]+1]\n",
    "    #   IP = unitary_Gauss(wav_extended[indexes[0]:indexes[-1]+1], wav, FWHM)\n",
    "    #   flux_conv_res.append(np.sum(IP*flux_2convolve))\n",
    "    if parallel_workers:\n",
    "        # If given workes to use\n",
    "         parallel_result = parallel_workers(delayed(convolve)(wav,R,wav_extended, flux_extended,FWHM_lim) for wav in wav_chip)\n",
    "    else:\n",
    "        parallel_result = Parallel(n_jobs=n_jobs)(delayed(convolve)(wav,R,wav_extended, flux_extended,FWHM_lim) for wav in wav_chip)\n",
    "    flux_conv_res = np.array(parallel_result, dtype=\"float64\")\n",
    "    print(\"Done.\\n\")\n",
    "    \n",
    "    \n",
    "    return wav_chip, flux_conv_res \n",
    "\n",
    "\n",
    "-\n",
    "print(\"function done\")\n",
    "print(\"function done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Try parrellel processing for the convolution\n",
    "\n",
    " from math import sqrt\n",
    " from joblib import Parallel, delayed\n",
    " Parallel(n_jobs=2)(delayed(sqrt)(i ** 2) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "start = time.time()\n",
    "print(\"start time\", datetime.datetime.now().time())\n",
    "\n",
    "%prun parallel_x, parallel_y = parallel_convolution(tapas_h20_data[0], tapas_h20_data[1], \"1\", 50000, FWHM_lim=5.0, n_jobs=-1)\n",
    "  \n",
    "done = time.time()\n",
    "print(\"end time\", datetime.datetime.now().time())\n",
    "elapsed = done - start\n",
    "print(\"Convolution time = \", elapsed)\n",
    "\n",
    "\n",
    "### Need to try running this code as a script not in the notebook to see if it works and is faster.\n",
    "#Will be benificial if trying to find the best scaling factor\n",
    "\n",
    "#Maybe good idea to find a general rule of thumb for height/depth of lines need to get to \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test passing it hte parallel worker\n",
    "start = time.time()\n",
    "with Parallel(n_jobs=-1, verbose=1) as parallel:\n",
    "    par_x, par_y = parallel_convolution(tapas_h20_data[0], tapas_h20_data[1], \"1\", 50000, FWHM_lim=5.0, n_jobs=-1, parallel_workers=parallel)\n",
    "  \n",
    "done = time.time()\n",
    "print(\"Convolution time = \", done - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "start = time.time()\n",
    "print(\"start time\", datetime.datetime.now().time())\n",
    "\n",
    "parallel_fast_x, parallel_fast_y = fast_convolution(tapas_h20_data[0], tapas_h20_data[1], \"1\", 50000, FWHM_lim=5.0)\n",
    "  \n",
    "done = time.time()\n",
    "print(\"end time\", datetime.datetime.now().time())\n",
    "elapsed = done - start\n",
    "print(\"Convolution time for rast convolution = \", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving a result for comparison\n",
    "\n",
    "#np.savetxt(\"Convolved_50000_tapas_wavelength_allchips.txt\", parallel_x)\n",
    "#np.savetxt(\"Convolved_50000_tapas_transmitance_allchips.txt\", parallel_y)\n",
    "\n",
    "#np.savetxt(\"Convolved_50000_tapas_wavelength_allchips_dividebynumber.txt\", parallel_x)\n",
    "#np.savetxt(\"Convolved_50000_tapas_transmitance_allchips_dividebynumber.txt\", parallel_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Parallel processing convolution times.\n",
    "\n",
    "### Windows laptop\n",
    "Convolution time =  868.3053071498871   # parallel code 1 process\n",
    "\n",
    "Convolution time =  981.6766209602356   # parallel 2 jobs, backend=\"threading\"\n",
    "\n",
    "Convolution time =  899.5289189815521   # parallel -1 jobs, backend=\"threading\"\n",
    "\n",
    "Convolution time =  2408.0208117961884  # parallel n_jobs=4, backend=\"threading\"   ~40min\n",
    "\n",
    "Convolution time =  983.7938089370728   # n_jobs=1, backend=\"threading\"   ~16min\n",
    "\n",
    "\n",
    "### Linux Work comp\n",
    "Convolution time =  54.9865338802               # n_jobs=-1\n",
    "\n",
    "Convolution time =  184.560889959               # n_jobs=1      ~ 3 min\n",
    "\n",
    "Convolution time =  99.8279280663               # n_jobs=2      ~ 1.5 min \n",
    "\n",
    "Convolution time =  68.0848469734               # n_jobs=3      ~ 1 min\n",
    "\n",
    "Convolution time =  56.3469331264               # n_jobs=4      < 1 min\n",
    "\n",
    "Convolution time =  253.075296164             # Work comp  # n_jobs=-1, backend=\"threading\"\n",
    "\n",
    "\n",
    "### All chips at once - condition \"0\"\n",
    "linux on parallel  \n",
    "Convolution time =  1150.128829s\n",
    "\n",
    "\n",
    "\n",
    "My conclusion is that joblib does a great job and increase the convolution speed for this task on linux. Threading is not good for this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(tapas_h20_data[0], tapas_h20_data[1], \"b\")\n",
    "#plt.plot(x,y/np.max(y), \"r\")\n",
    "plt.plot(parallel_x, parallel_y, \"-r\")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Flux\")\n",
    "plt.title(\"Test of convolutions\")\n",
    "#plt.show()\n",
    "# Make it interactive with Bokeh\n",
    "bokeh.plotting.show(bokeh.mpl.to_bokeh())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit best scaling power.\n",
    "Does each chip need a differnet scaling power?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lmfit import minimize, Parameters\n",
    "import lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "def match_wl(wl, spec, ref_wl, method=\"scipy\", kind=\"linear\"):\n",
    "    \"\"\"Interpolate Wavelengths of spectra to common WL\n",
    "    Most likely convert telluric to observed spectra wl after wl mapping performed\"\"\"\n",
    "    starttime = time.time()\n",
    "    if method == \"scipy\":\n",
    "        print(kind + \" scipy interpolation\")\n",
    "        linear_interp = interp1d(wl, spec, kind=kind)\n",
    "        new_spec = linear_interp(ref_wl)\n",
    "    elif method == \"numpy\":\n",
    "        if kind.lower() is not \"linear\":\n",
    "            print(\"Warning: Cannot do \" + kind + \" interpolation with numpy, switching to linear\" )\n",
    "        print(\"Linear numpy interpolation\")\n",
    "        new_spec = np.interp(ref_wl, wl, spec)  # 1-d peicewise linear interpolat\n",
    "    else:\n",
    "        print(\"Method was given as \" + method)\n",
    "        raise(\"Not correct interpolation method specified\")\n",
    "    print(\"Interpolation Time = \" + str(time.time() - starttime) + \" seconds\")\n",
    "\n",
    "    return new_spec  # test inperpolations \n",
    "\n",
    "def slice_spectra(wl, spectrum, low, high):\n",
    "    \"\"\" Extract a section of a spectrum between wavelength bounds. \n",
    "        \"\"\"\n",
    "    #print(\"lower bound\", low)\n",
    "    #print(\"upper bound\", high)\n",
    "    map1 = wl > low\n",
    "    map2 = wl < high\n",
    "    wl_sec = wl[map1*map2]\n",
    "    spectrum_sec = spectrum[map1*map2]   \n",
    "    return wl_sec, spectrum_sec \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Fit using lmfit\n",
    "# parallel version of h20 residuals before np speed up.\n",
    "# bad as it has the Parallel creation inside the fit function / was fixed at work but don't know how these will merge\n",
    "def h20_residual(params, obs_data, telluric_data):\n",
    "    # Parameters \n",
    "    ScaleFactor = params[\"ScaleFactor\"].value\n",
    "    R = params[\"R\"].value\n",
    "    FWHM_lim = params[\"FWHM_lim\"].value\n",
    "    n_jobs = params[\"n_jobs\"].value  # parallel implementaiton\n",
    "    chip_select = params[\"chip_select\"].value\n",
    "    parallel_workers = params[\"parallel_workers\"].value  # Joblib parallel worker\n",
    "    \n",
    "    # Data\n",
    "    obs_wl = obs_data[0]\n",
    "    obs_I = obs_data[1]\n",
    "    telluric_wl = telluric_data[0]\n",
    "    telluric_I = telluric_data[1]\n",
    "    \n",
    "    # Telluric scaling T ** x\n",
    "    scaled_telluric_I = telluric_I ** ScaleFactor\n",
    "    \n",
    "    # Convolution\n",
    "    convolved_telluric = parallel_convolution(telluric_wl, scaled_telluric_I, str(chip_select), R, FWHM_lim=FWHM_lim, n_jobs=n_jobs, parallel_workers=parallel_workers)\n",
    "    interped_telluric = match_wl(telluric_wl, telluric_I, obs_wl)\n",
    "    print(\"Convolution inside residual function was done\")\n",
    "    \n",
    "    return 1 - (obs_I / convolved_telluric) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up parameters \n",
    "params = Parameters()\n",
    "params.add('ScaleFactor', value=1)\n",
    "params.add('R', value=50000, vary=False)\n",
    "params.add('FWHM_lim', value=5, vary=False)\n",
    "params.add('n_jobs', value=-1, vary=False)\n",
    "params.add('chip_select', value=2, vary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wl2, I2_uncorr\n",
    "# wl2, I2_not_h20_corr\n",
    "\n",
    "# Sliced to wavelength measurement of detector\n",
    "tell_data1 = fast_wav_selector(tapas_h20_data[0], tapas_h20_data[1], 0.95*min(wl1), 1.05*max(wl1))\n",
    "tell_data2 = fast_wav_selector(tapas_h20_data[0], tapas_h20_data[1], 0.95*min(wl2), 1.05*max(wl2))\n",
    "tell_data3 = fast_wav_selector(tapas_h20_data[0], tapas_h20_data[1], 0.95*min(wl3), 1.05*max(wl3))\n",
    "tell_data4 = fast_wav_selector(tapas_h20_data[0], tapas_h20_data[1], 0.95*min(wl4), 1.05*max(wl4))\n",
    "\n",
    "               \n",
    "print(\"Number of values to iterate\", len(tell_data2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test outside of fit\n",
    "print(\"Starting test\")\n",
    "with Parallel(n_jobs=-1, verbose=1) as parallel:\n",
    "    params.add('parallel_workers', value=parallel, vary=False)\n",
    "    residual = h20_residual(params,[wl2, I2_not_h20_corr], tell_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Peform minimization\n",
    "with Parallel(n_jobs=-1) as parallel:\n",
    "    params.add('parallel_workers', value=parallel, vary=False)\n",
    "    out = minimize(h20_residual, params, args=([wl2, I2_not_h20_corr], tell_data2))\n",
    "outreport = lmfit.fit_report(out)\n",
    "print(outreport)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing test of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Time difference between my slice spectra and pedros wave selector\n",
    "%timeit wav_selector(tapas_h20_data[0], tapas_h20_data[1], min(wl1), max(wl4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit slice_spectra(tapas_h20_data[0], tapas_h20_data[1], min(wl1), max(wl4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore Pedros wav_selector is faster/more efficent than my code. Should adjust my code accordingly.\n",
    "I should probably move this to a different notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply correction with best scaling power:\n",
    "\n",
    "And plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
